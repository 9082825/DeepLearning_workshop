{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8916ed",
   "metadata": {},
   "source": [
    "## üß† Case Study: Are We Going to Canada's Wonderland?\n",
    "We will now implement a simple artificial neural network using **PyTorch** to predict whether we‚Äôll go to Canada's Wonderland based on three inputs:\n",
    "\n",
    "- **X‚ÇÅ**: Weather ‚Äî 1 if sunny, 0 if rainy\n",
    "- **X‚ÇÇ**: Ticket queue ‚Äî 1 if short, 0 if long\n",
    "- **X‚ÇÉ**: Health ‚Äî 1 if healthy, 0 if unwell\n",
    "\n",
    "Each input has an associated **weight**, and the network uses a **bias** and a **sigmoid activation function** to generate a confidence value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75b661",
   "metadata": {},
   "source": [
    "### üî¢ Step 1: Prediction Function\n",
    "We compute the neuron output $\\hat{y}$ as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad \\text{where} \\quad z = w_1 x_1 + w_2 x_2 + w_3 x_3 + b\n",
    "$$\n",
    "\n",
    "In our case:\n",
    "\n",
    "- $x = [1, 0, 1]$\n",
    "- $w = [5, 2, 4]$\n",
    "- $b = -3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84765486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Inputs and weights\n",
    "x = torch.tensor([1.0, 0.0, 1.0])\n",
    "weights = torch.tensor([5.0, 2.0, 4.0])\n",
    "bias = -3.0\n",
    "\n",
    "# Linear combination\n",
    "z = torch.dot(weights, x) + bias\n",
    "\n",
    "# Sigmoid activation\n",
    "sigmoid = torch.sigmoid(z)\n",
    "print(f\"z = {z.item():.2f}\")\n",
    "print(f\"Predicted output (sigmoid) = {sigmoid.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce17f0",
   "metadata": {},
   "source": [
    "### üí¨ Talking Points\n",
    "- We treat inputs like \"sunny\", \"short queue\", and \"healthy\" as binary features.\n",
    "- The weighted sum (`z`) captures how favorable conditions are.\n",
    "- Applying `sigmoid(z)` maps the decision to a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcc169",
   "metadata": {},
   "source": [
    "### ‚ùå Step 2: Error Calculation\n",
    "We compare the predicted value with the actual label:\n",
    "\n",
    "$$\n",
    "E = y - \\hat{y}\n",
    "$$\n",
    "\n",
    "If the actual value is 1 (we should go), but our prediction is too low, we compute the error and update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(1.0)\n",
    "error = y - sigmoid\n",
    "print(f\"Error = {error.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbf504",
   "metadata": {},
   "source": [
    "### üîÅ Step 3: Weight Update with Gradient Descent\n",
    "Using a learning rate $\\eta = 0.1$, we update each weight:\n",
    "\n",
    "$$\n",
    "w_j = w_j - \\eta \\cdot \\frac{\\partial L}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "We use PyTorch autograd to perform backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.clone().detach().requires_grad_(True)\n",
    "weights = weights.clone().detach().requires_grad_(True)\n",
    "\n",
    "z = torch.dot(weights, x) + bias\n",
    "y_hat = torch.sigmoid(z)\n",
    "loss = (y_hat - y) ** 2\n",
    "loss.backward()\n",
    "\n",
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    weights -= lr * weights.grad\n",
    "    print(f\"Updated weights: {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942192e",
   "metadata": {},
   "source": [
    "> ### üè† Homework Challenge\n",
    ">\n",
    "> Study how to update the weights using **Gradient Descent**.\n",
    ">\n",
    "> üìå **Question**: How is this update rule related to **Backpropagation** in multi-layer neural networks?\n",
    ">\n",
    "> (You may remove the solution cell below when presenting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Descent computes how to change each weight to reduce the loss.\")\n",
    "print(\"Backpropagation extends this to multiple layers using the chain rule.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f71ef",
   "metadata": {},
   "source": [
    "### üßÆ Step 3: Weight Update with Gradient Descent ‚Äî A Closer Look and soltution to the challenge\n",
    "\n",
    "Once we compute the **loss** (difference between the predicted output and actual target), the next step is to **update the weights** so that the network improves its predictions. This is done using **gradient descent**.\n",
    "\n",
    "### üìâ Gradient Descent: The Core Idea\n",
    "\n",
    "We want to **minimize the loss function** $ L $ by adjusting the weights $ w_j $. Gradient descent helps us do this by computing how much the loss changes with respect to each weight ‚Äî this is the **partial derivative**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "This derivative tells us:\n",
    "\n",
    "> \"If I increase weight $ w_j $ just a little, will the loss go up or down? And by how much?\"\n",
    "\n",
    "### üß™ The Update Rule\n",
    "\n",
    "To reduce the loss, we **move each weight** in the opposite direction of the gradient. That‚Äôs where the gradient descent update rule comes in:\n",
    "\n",
    "$$\n",
    "w_j = w_j - \\eta \\cdot \\frac{\\partial L}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $ w_j $ is the weight for feature $ j $\n",
    "* $ \\eta $ is the **learning rate** ‚Äî a small number like `0.1` that controls how big each update step is\n",
    "* $ \\frac{\\partial L}{\\partial w_j} $ is the gradient (i.e., how sensitive the loss is to changes in $ w_j $)\n",
    "\n",
    "### üîç Why Subtract the Gradient?\n",
    "\n",
    "* The **gradient** points in the direction that **increases** the loss.\n",
    "* We want to **minimize** the loss.\n",
    "* So, we go in the **opposite** direction ‚Äî that‚Äôs why we subtract.\n",
    "\n",
    "### üß† Learning Rate $ \\eta $: The Step Size\n",
    "\n",
    "* If $ \\eta $ is **too large**, we might overshoot the minimum ‚Äî the network will not converge.\n",
    "* If $ \\eta $ is **too small**, learning will be very slow.\n",
    "* A value like $ \\eta = 0.1 $ is a reasonable starting point for simple problems.\n",
    "\n",
    "Think of gradient descent as walking downhill:\n",
    "\n",
    "* The gradient tells you **which way is down**.\n",
    "* The learning rate tells you **how big a step to take**.\n",
    "\n",
    "### üîÅ PyTorch Makes It Easy\n",
    "\n",
    "When using PyTorch:\n",
    "\n",
    "1. We compute the loss.\n",
    "2. We call `loss.backward()` ‚Äî this uses **autograd** to compute all the gradients.\n",
    "3. Then, PyTorch updates the weights automatically using:\n",
    "\n",
    "```python\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "Behind the scenes, it's doing:\n",
    "\n",
    "$$\n",
    "w_j = w_j - \\eta \\cdot \\frac{\\partial L}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "This is how the model **learns** from examples and improves predictions.\n",
    "\n",
    "‚úÖ **Key Insight**: Gradient descent is what allows neural networks to learn from data. It systematically tweaks the weights so the network gets better at solving its task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cd987",
   "metadata": {},
   "source": [
    "### üîÅ Let's revisit backpropagation:\n",
    "\n",
    "![Slide 5](./images/ANN_5.png)\n",
    "\n",
    "### üîÅ Step 3 (continued): How Gradient Descent Updates Weights ‚Äî Slide 5 Breakdown\n",
    "\n",
    "In **Slide 5**, we see that the network made a prediction:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 6\n",
    "$$\n",
    "\n",
    "But the **actual target** was:\n",
    "\n",
    "$$\n",
    "y = 1\n",
    "$$\n",
    "\n",
    "So the **error** is:\n",
    "\n",
    "$$\n",
    "E = y - \\hat{y} = 1 - 6 = -5\n",
    "$$\n",
    "\n",
    "Even though the sigmoid activation produces a value close to 1 (as seen in earlier steps), this diagram continues the exercise **without** applying sigmoid ‚Äî instead, it treats the raw output $ \\hat{y} $ directly for didactic purposes.\n",
    "\n",
    "### ‚öôÔ∏è Applying the Gradient Descent Update Rule\n",
    "\n",
    "The formula used is:\n",
    "\n",
    "$$\n",
    "w_j^{\\text{new}} = w_j^{\\text{old}} - \\eta \\cdot \\frac{\\partial L}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "Let's assume:\n",
    "\n",
    "* Learning rate $ \\eta = 0.1 $\n",
    "* We use the squared error loss:\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{2}(y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "Its gradient w.r.t. $ w_j $ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_j} = (y - \\hat{y}) \\cdot \\frac{\\partial \\hat{y}}{\\partial w_j} = (y - \\hat{y}) \\cdot x_j\n",
    "$$\n",
    "\n",
    "### üßÆ Step-by-Step Weight Update Calculations\n",
    "\n",
    "We know:\n",
    "\n",
    "* $ y = 1 $\n",
    "* $ \\hat{y} = 6 $\n",
    "* Error: $ y - \\hat{y} = -5 $\n",
    "* Inputs: $ x = [1, 0, 1] $\n",
    "* Initial weights: $ w_1 = 5, w_2 = 2, w_3 = 4 $\n",
    "\n",
    "#### üîπ Weight 1 Update:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_1} = -5 \\cdot 1 = -5\n",
    "$$\n",
    "$$\n",
    "w_1^{\\text{new}} = 5 - 0.1 \\cdot (-5) = 5 + 0.5 = 5.5\n",
    "$$\n",
    "\n",
    "#### üîπ Weight 2 Update:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_2} = -5 \\cdot 0 = 0\n",
    "$$\n",
    "$$\n",
    "w_2^{\\text{new}} = 2 - 0.1 \\cdot 0 = 2\n",
    "$$\n",
    "\n",
    "#### üîπ Weight 3 Update:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_3} = -5 \\cdot 1 = -5\n",
    "$$\n",
    "$$\n",
    "w_3^{\\text{new}} = 4 - 0.1 \\cdot (-5) = 4 + 0.5 = 4.5\n",
    "$$\n",
    "\n",
    "### ‚úÖ Updated Weights:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w_1 &= 5.5 \\\n",
    "w_2 &= 2.0 \\\n",
    "w_3 &= 4.5 \\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "These new weights will produce a smaller output $ \\hat{y} $ in the next forward pass ‚Äî helping the network move **closer to the correct target** and reducing error.\n",
    "\n",
    "### üß† Intuition from Slide 7\n",
    "\n",
    "Slide 7 (below) illustrates this process visually ‚Äî we are using the **gradient** of the loss function to adjust weights in a way that reduces prediction error. This is how a neural network learns: it adjusts its parameters to better match real outcomes.\n",
    "\n",
    "### üîÅ Let's revisit backpropagation:\n",
    "\n",
    "![Slide 5](./images/ANN_7.png)\n",
    "\n",
    "### üîÅ **We‚Äôll continue doing this in a loop, until the error is acceptably small.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
